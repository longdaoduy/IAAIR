# Hybrid Search Implementation

## Overview

This implementation upgrades the IAAIR system to use **hybrid search** instead of just semantic search. Hybrid search combines:

1. **Dense Vector Search** - SciBERT embeddings for semantic similarity
2. **Sparse Vector Search** - TF-IDF embeddings for keyword/lexical matching
3. **RRF (Reciprocal Rank Fusion)** - Intelligent ranking fusion

## Key Features

### üéØ Hybrid Search Benefits
- **Better Recall**: Finds papers that are semantically similar OR contain matching keywords
- **Improved Precision**: RRF ranking combines both signals for better results
- **Flexibility**: Can switch between hybrid and dense-only search
- **Robust**: Falls back to dense search if sparse search fails

### üèóÔ∏è Architecture Changes

#### 1. Updated Milvus Schema
```python
fields = [
    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="abstract", dtype=DataType.VARCHAR, max_length=8000),
    FieldSchema(name="dense_embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="sparse_embedding", dtype=DataType.SPARSE_FLOAT_VECTOR)
]
```

#### 2. Dual Indexing
- **Dense Index**: IVF_FLAT with cosine similarity
- **Sparse Index**: SPARSE_INVERTED_INDEX with inner product

#### 3. TF-IDF Configuration
```python
TfidfVectorizer(
    max_features=10000,
    stop_words='english', 
    lowercase=True,
    ngram_range=(1, 2)  # Unigrams and bigrams
)
```

## API Changes

### Search Endpoint Parameters
```json
{
  "query": "machine learning neural networks",
  "top_k": 10,
  "include_details": true,
  "use_hybrid": true  // NEW: Enable hybrid search
}
```

### Response Format
Results now include:
- `search_type`: "hybrid" or "dense_only"
- `title` and `abstract`: Stored in Milvus for better performance
- Enhanced similarity scoring from RRF

## Implementation Details

### 1. Sparse Embedding Generation
```python
def generate_sparse_embedding(self, text: str) -> Dict[int, float]:
    """Generate TF-IDF sparse embedding."""
    tfidf_vector = self.tfidf_vectorizer.transform([text])
    # Convert to Milvus sparse format: {index: value}
    sparse_dict = {}
    coo_matrix = tfidf_vector.tocoo()
    for i, j, val in zip(coo_matrix.row, coo_matrix.col, coo_matrix.data):
        if val > 0.01:  # Filter noise
            sparse_dict[j] = float(val)
    return sparse_dict
```

### 2. Hybrid Search Process
```python
def _hybrid_search(self, query_text: str, dense_embedding: List[float], top_k: int):
    # 1. Generate sparse embedding
    sparse_embedding = self.generate_sparse_embedding(query_text)
    
    # 2. Create search requests
    dense_request = AnnSearchRequest(data=[dense_embedding], anns_field="dense_embedding", ...)
    sparse_request = AnnSearchRequest(data=[sparse_embedding], anns_field="sparse_embedding", ...)
    
    # 3. Perform hybrid search with RRF ranking
    results = self.collection.hybrid_search(
        reqs=[dense_request, sparse_request],
        rerank=RRFRanker(),
        limit=top_k
    )
    return results
```

### 3. Data Upload Process
1. **Dense Embeddings**: Generated using SciBERT
2. **Sparse Embeddings**: Generated using TF-IDF fitted on corpus
3. **Text Storage**: Title and abstract stored for retrieval
4. **Batch Processing**: Efficient upload with proper indexing

## Performance Considerations

### Memory Usage
- **Dense vectors**: 768 √ó 4 bytes = ~3KB per paper
- **Sparse vectors**: ~50-200 non-zero features = ~800 bytes per paper  
- **Text storage**: ~1-8KB per paper
- **Total**: ~5-12KB per paper

### Search Performance
- **Hybrid search**: Slightly slower than dense-only (~1.2x)
- **Better results**: Improved recall and precision
- **Fallback**: Graceful degradation to dense search

## Migration Guide

### For Existing Data
1. **Backup**: Current Milvus collections will be recreated
2. **Reprocess**: Papers need re-uploading with new schema
3. **API**: Existing calls work (defaults to hybrid search)

### Configuration
- Set `use_hybrid=false` to use dense-only search
- TF-IDF vectorizer automatically fits on uploaded corpus
- No additional configuration required

## Testing

Run the test script to verify functionality:
```bash
python test_hybrid_search.py
```

## Dependencies Added
- `scikit-learn==1.6.0` - For TF-IDF vectorization
- `scipy==1.16.1` - For sparse matrix operations

## Usage Examples

### Python Client
```python
# Hybrid search (default)
results = milvus_client.search_similar_papers(
    query_text="deep learning transformers",
    top_k=10,
    use_hybrid=True
)

# Dense-only search
results = milvus_client.search_similar_papers(
    query_text="deep learning transformers", 
    top_k=10,
    use_hybrid=False
)
```

### API Request
```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "neural networks for NLP",
    "top_k": 5,
    "use_hybrid": true
  }'
```

## Benefits Summary

1. **üéØ Better Results**: Combines semantic + keyword matching
2. **üîÑ Backward Compatible**: Existing API calls still work  
3. **‚ö° Flexible**: Can switch between hybrid/dense search
4. **üõ°Ô∏è Robust**: Automatic fallback mechanisms
5. **üìà Scalable**: Efficient sparse vector handling
6. **üé® User-Friendly**: Simple API parameter to control search type

The hybrid search implementation provides significantly better search results by combining the semantic understanding of SciBERT with the keyword precision of TF-IDF, all seamlessly integrated into the existing IAAIR system.